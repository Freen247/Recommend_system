{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 包的导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "import os, sys, time \n",
    "\n",
    "\n",
    "print(sys.version_info)\n",
    "for module in tf, mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集的准备\n",
    "Fashion-MNIST是一个替代MNIST手写数字集的图像数据集。 它是由Zalando（一家德国的时尚科技公司）旗下的研究部门提供。其涵盖了来自10种类别的共7万个不同商品的正面图片。Fashion-MNIST的大小、格式和训练集/测试集划分与原始的MNIST完全一致。60000/10000的训练测试数据划分，28x28的灰度图片。你可以直接用它来测试你的机器学习和深度学习算法性能，且不需要改动任何的代码。\n",
    "- 60000张训练图像和对应Label；\n",
    "- 10000张测试图像和对应Label；\n",
    "- 10个类别；\n",
    "- 每张图像28x28的分辨率；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(x_train_all, y_train_all), (x_test, y_test) = fashion_mnist.load_data()\n",
    "# fashion_mnist 训练集共有60000，将前5000作为验证集，后55000作为训练集\n",
    "x_valid, x_train = x_train_all[:5000], x_train_all[5000:]\n",
    "y_valid, y_train = y_train_all[:5000], y_train_all[5000:]\n",
    "\n",
    "print(\"x_valid.shape, y_valid.shape:\",x_valid.shape, y_valid.shape)\n",
    "print(\"x_train.shape, y_train.shape\",x_train.shape, y_train.shape)\n",
    "print(\"x_test.shape, y_test.shape\",x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集样本展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-4137d15a81f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mshow_single_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "# 数据集样本展示\n",
    "def show_single_img(img_arr):\n",
    "    plt.imshow(img_arr, cmap=\"binary\")\n",
    "    plt.show()\n",
    "show_single_img(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对数据进行归一化处理\n",
    "> 定义：把数据经过处理后使之限定在一定的范围内。比如通常限制在区间`[0, 1]`或者`[-1, 1]`\n",
    "\n",
    "常用归一化法：\n",
    "- 最大-最小标准化: $$\\frac{x-x_{min}}{x_{max}-x_{min}}$$\n",
    "- Z-score标准化: $$\\frac{x-\\mu }{std} \\left ( \\mu为标准差 ,std 为方差 \\right ) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "对数据进行归一化处理\n",
    "定义：把数据经过处理后使之限定在一定的范围内。比如通常限制在区间[0, 1]或者[-1, 1]\n",
    "Z-score归一化\n",
    "'''\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# x_train:[None, 28, 28] -> [None, 784]\n",
    "# 我们np里的数据是int类型，所以我们需要x_train.astype(np.float32)将数据转化成float32\n",
    "# fit_transform 不仅有数据转化为归一化的功能，还有fit（将数据存储下来）的功能.\n",
    "Z_score = lambda d:scaler.fit_transform(d.astype(np.float32).reshape(-1,1)).reshape(-1,28,28)\n",
    "x_train_scaled = Z_score(x_train)\n",
    "x_valid_scaled = Z_score(x_valid)\n",
    "x_test_scaled = Z_score(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型的构建\n",
    "tf.keras.models.sequential()\n",
    "普通的模型构建：\n",
    "```\n",
    "model = keras.models.Sequential([\n",
    "    # 第一层输入成，每一个组数据为[28,28]的二维矩阵，通过keras.layers.Flatten压缩成一维矩阵\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    keras.layers.Dense(300, activation = \"relu\"),\n",
    "    keras.layers.Dense(100, activation = \"relu\"),\n",
    "    keras.layers.Dense(10, activation = \"softmax\"),\n",
    "])\n",
    "```\n",
    "批归一化加激活函数模型构建：\n",
    "\n",
    "```\n",
    "model.add(keras.layers.Flatten(input_shape=[28,28]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100,activation='relu'))\n",
    "    # 批归一化\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    '''\n",
    "    model.add(keras.layers.Dense(100))\n",
    "    # 将批归一化放在激活函数之前\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    # 我们还可以将激活函数设置为一个层次\n",
    "    model.add(keras.layers.Activation('selu'))\n",
    "    model.add(keras.layers.Dense(10,activation='softmax'))\n",
    "    '''\n",
    "```\n",
    "\n",
    "添加dropout层，一般情况下我们只在最后几层添加dropout："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型的构建\n",
    "# tf.keras.models.sequential()\n",
    "# 将 28*28 的矩阵展开为一维向量\n",
    "print('训练集中第0个数据：',x_train[0].shape)\n",
    "# deep_neural_network模型的构建(20层)\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28,28]))\n",
    "for _ in range(20):\n",
    "    # 其中selu是一个自带归一化的激活函数,会在\n",
    "    model.add(keras.layers.Dense(100,activation='selu'))\n",
    "# AlphaDropout相比 强大在：1，均值和方差不变 2.归一化的性质不变，分布不会发生变化，可以和批归一化一起使用\n",
    "model.add(keras.layers.AlphaDropout(rate=0.5,))\n",
    "# model.add(keras.layers.Dropout(rate=0.5))\n",
    "model.add(keras.layers.Dense(10,activation='softmax'))\n",
    "\n",
    "# reason for sparse : y->index, y->one_hot->[],我们需要将y处理成one_hot向量所以用sparse\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer='sgd', metrics= ['accuracy'])\n",
    "# 定义的模型中的所有层\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据的训练\n",
    "### [添加回调函数pg](https://tensorflow.google.cn/api_docs/python/tf/keras/callbacks?hl=zh_cn)\n",
    "- Tensorboard: \n",
    "    - Metrics summary plots 指标摘要图\n",
    "    - Training graph visualization 训练图可视化\n",
    "    - Activation histograms 激活直方图\n",
    "    - Sampled profiling 采样分析\n",
    "- EarlyStopping \n",
    "    - 关注某个指标，比如超参\n",
    "        超参数之一是定型周期（epoch）的数量：亦即应当完整遍历数据集多少次（一次为一个epoch）？如果epoch数量太少，网络有可能发生欠拟合（即对于定型数据的学习不够充分）；如果epoch数量太多，则有可能发生过拟合（即网络对定型数据中的“噪声”而非信号拟合）。\n",
    "\n",
    "    早停法旨在解决epoch数量需要手动设置的问题。它也可以被视为一种能够避免网络发生过拟合的正则化方法（与L1/L2权重衰减和丢弃法类似）。\n",
    "\n",
    "    根本原因就是因为继续训练会导致测试集上的准确率下降。\n",
    "    那继续训练导致测试准确率下降的原因猜测可能是1. 过拟合 2. 学习率过大导致不收敛\n",
    "\n",
    "### 对layers进行数据训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 回调函数\n",
    "logdir = './callbacks'\n",
    "if not os.path.exists(logdir):\n",
    "    os.mkdir(logdir)\n",
    "output_modle_file = os.path.join(logdir, \"fashion_mnist_model.h5\")\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.TensorBoard(logdir),\n",
    "    keras.callbacks.ModelCheckpoint(output_modle_file, save_best_only = True),\n",
    "    # 由于epochs设置的比较小，可能不会触发，可以将epochs调大点，看看EarlyStopping的运行情况\n",
    "    keras.callbacks.EarlyStopping(patience=5, min_delta=1e-3),\n",
    "]\n",
    "# 数据的训练\n",
    "history = model.fit(x_train_scaled, y_train, epochs=10,validation_data=(x_valid_scaled,y_valid))\n",
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## matloplib可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matloplib可视化\n",
    "def plot_learning_cruves(history):\n",
    "    pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "    plt.grid(True)\n",
    "    plt.gca().set_ylim(0,1)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加上Z_scores归一化,dnn后的损失图像：\n",
    "plot_learning_cruves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "### 关于梯度消失问题\n",
    "深度模型中可能出现的问题：参数众多，倒只训练不充分\n",
    "梯度消失问题：首先梯度下降是指，一个数按照其此点最大导数的反方向更新。\n",
    "对于一个多层次的神经网络来说，比目标函数比较远的但是梯度比较微小的现象。\n",
    "什么情况会导致？ 一般发生在深度模型中，根据链式法则：符合函数{f(g(x))}\n",
    "梯度下降的时候我们需要对每一个嵌套的复合函数进行求导再相乘，最后如果求出来的导数小于1，多此相乘就会导致梯度消失。\n",
    "1.01^99=37.8\n",
    "0.99^99=0.03\n",
    "\n",
    "批归一化可以在一定程度上缓解梯度消失~\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.6.7 64-bit ('rec_env': virtualenv)",
   "language": "python",
   "name": "python36764bitrecenvvirtualenvc590a763a4564b6f98e8e2c90348aa96"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}