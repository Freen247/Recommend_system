{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 包的导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=6, micro=7, releaselevel='final', serial=0)\n",
      "tensorflow 2.1.0\n",
      "matplotlib 3.2.0\n",
      "numpy 1.18.1\n",
      "pandas 1.0.1\n",
      "sklearn 0.22.2.post1\n",
      "tensorflow 2.1.0\n",
      "tensorflow_core.python.keras.api._v2.keras 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "import os, sys, time \n",
    "\n",
    "\n",
    "print(sys.version_info)\n",
    "for module in tf, mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集的准备\n",
    "Fashion-MNIST是一个替代MNIST手写数字集的图像数据集。 它是由Zalando（一家德国的时尚科技公司）旗下的研究部门提供。其涵盖了来自10种类别的共7万个不同商品的正面图片。Fashion-MNIST的大小、格式和训练集/测试集划分与原始的MNIST完全一致。60000/10000的训练测试数据划分，28x28的灰度图片。你可以直接用它来测试你的机器学习和深度学习算法性能，且不需要改动任何的代码。\n",
    "- 60000张训练图像和对应Label；\n",
    "- 10000张测试图像和对应Label；\n",
    "- 10个类别；\n",
    "- 每张图像28x28的分辨率；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_valid.shape, y_valid.shape: (5000, 28, 28) (5000,)\n",
      "x_train.shape, y_train.shape (55000, 28, 28) (55000,)\n",
      "x_test.shape, y_test.shape (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(x_train_all, y_train_all), (x_test, y_test) = fashion_mnist.load_data()\n",
    "# fashion_mnist 训练集共有60000，将前5000作为验证集，后55000作为训练集\n",
    "x_valid, x_train = x_train_all[:5000], x_train_all[5000:]\n",
    "y_valid, y_train = y_train_all[:5000], y_train_all[5000:]\n",
    "\n",
    "print(\"x_valid.shape, y_valid.shape:\",x_valid.shape, y_valid.shape)\n",
    "print(\"x_train.shape, y_train.shape\",x_train.shape, y_train.shape)\n",
    "print(\"x_test.shape, y_test.shape\",x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集样本展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 数据集样本展示\n",
    "def show_single_img(img_arr):\n",
    "    plt.imshow(img_arr, cmap=\"binary\")\n",
    "    plt.show()\n",
    "show_single_img(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对数据进行归一化处理\n",
    "> 定义：把数据经过处理后使之限定在一定的范围内。比如通常限制在区间`[0, 1]`或者`[-1, 1]`\n",
    "\n",
    "常用归一化法：\n",
    "- 最大-最小标准化: $$\\frac{x-x_{min}}{x_{max}-x_{min}}$$\n",
    "- Z-score标准化: $$\\frac{x-\\mu }{std} \\left ( \\mu为标准差 ,std 为方差 \\right ) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "对数据进行归一化处理\n",
    "定义：把数据经过处理后使之限定在一定的范围内。比如通常限制在区间[0, 1]或者[-1, 1]\n",
    "Z-score归一化\n",
    "'''\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# x_train:[None, 28, 28] -> [None, 784]\n",
    "# 我们np里的数据是int类型，所以我们需要x_train.astype(np.float32)将数据转化成float32\n",
    "# fit_transform 不仅有数据转化为归一化的功能，还有fit（将数据存储下来）的功能.\n",
    "Z_score = lambda d:scaler.fit_transform(d.astype(np.float32).reshape(-1,1)).reshape(-1,28,28)\n",
    "x_train_scaled = Z_score(x_train)\n",
    "x_valid_scaled = Z_score(x_valid)\n",
    "x_test_scaled = Z_score(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型的构建\n",
    "tf.keras.models.sequential()\n",
    "普通的模型构建：\n",
    "```\n",
    "model = keras.models.Sequential([\n",
    "    # 第一层输入成，每一个组数据为[28,28]的二维矩阵，通过keras.layers.Flatten压缩成一维矩阵\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    keras.layers.Dense(300, activation = \"relu\"),\n",
    "    keras.layers.Dense(100, activation = \"relu\"),\n",
    "    keras.layers.Dense(10, activation = \"softmax\"),\n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集中第0个数据： (28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x2231d445f98>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2231d4d1358>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x2231d5065c0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2231d506588>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x2231d961f28>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2231d96ec88>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x2231d990b00>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2231d990ac8>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x2231d9d0550>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2231d9d0518>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x2231d990b70>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2231d9d0630>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x22314e0d8d0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x22314df2198>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x2231d9d07f0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2237fb37240>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x2231d3c5c88>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2231d3c5f28>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x2231d42aa20>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2231d9dbfd0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x2231d9dbe10>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2231da429b0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x2231dbdcef0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2231dbe7d68>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x2231da42978>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2231dc0ed68>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x2231dc0efd0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2231dc3cac8>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x2231dc3ca90>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2231d4d1f60>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x2231dc6fe48>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2231deb9d30>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x2231deb9dd8>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2231deeab70>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x2231deeab38>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2231df1eeb8>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x2231df44e48>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2231df44e10>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x2231df1eef0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2231e3a3c18>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x2231e3a3be0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2231d4d1898>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型的构建\n",
    "# tf.keras.models.sequential()\n",
    "# 将 28*28 的矩阵展开为一维向量\n",
    "print('训练集中第0个数据：',x_train[0].shape)\n",
    "# deep_neural_network模型的构建(20层)\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28,28]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100,activation='selu'))\n",
    "    # 批归一化\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    '''\n",
    "    model.add(keras.layers.Dense(100))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation('selu'))\n",
    "    '''\n",
    "model.add(keras.layers.Dense(10,activation='softmax'))\n",
    "# model = keras.models.Sequential([\n",
    "#     # 第一层输入成，每一个组数据为[28,28]的二维矩阵，通过keras.layers.Flatten压缩成一维矩阵\n",
    "#     keras.layers.Flatten(input_shape=[28,28]),\n",
    "#     keras.layers.Dense(300, activation = \"relu\"),\n",
    "#     keras.layers.Dense(100, activation = \"relu\"),\n",
    "#     keras.layers.Dense(10, activation = \"softmax\"),\n",
    "# ])\n",
    "# relu: y = max(0, x)\n",
    "# softmax: 将向量变成概率分布 x = [x1,x2, x3]\n",
    "# y = [e^x1/sum, e^x2/sum, e^x3/sum]  sum = e^x1+e^x3+e^x3\n",
    "\n",
    "# reason for sparse : y->index, y->one_hot->[],我们需要将y处理成one_hot向量所以用sparse\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer='sgd', metrics= ['accuracy'])\n",
    "# 定义的模型中的所有层\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 279,410\n",
      "Trainable params: 275,410\n",
      "Non-trainable params: 4,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据的训练\n",
    "### [添加回调函数pg](https://tensorflow.google.cn/api_docs/python/tf/keras/callbacks?hl=zh_cn)\n",
    "- Tensorboard: \n",
    "    - Metrics summary plots 指标摘要图\n",
    "    - Training graph visualization 训练图可视化\n",
    "    - Activation histograms 激活直方图\n",
    "    - Sampled profiling 采样分析\n",
    "- EarlyStopping \n",
    "    - 关注某个指标，比如超参\n",
    "        超参数之一是定型周期（epoch）的数量：亦即应当完整遍历数据集多少次（一次为一个epoch）？如果epoch数量太少，网络有可能发生欠拟合（即对于定型数据的学习不够充分）；如果epoch数量太多，则有可能发生过拟合（即网络对定型数据中的“噪声”而非信号拟合）。\n",
    "\n",
    "    早停法旨在解决epoch数量需要手动设置的问题。它也可以被视为一种能够避免网络发生过拟合的正则化方法（与L1/L2权重衰减和丢弃法类似）。\n",
    "\n",
    "    根本原因就是因为继续训练会导致测试集上的准确率下降。\n",
    "    那继续训练导致测试准确率下降的原因猜测可能是1. 过拟合 2. 学习率过大导致不收敛\n",
    "\n",
    "### 对layers进行数据训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-494eb76ceada>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 回调函数\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mlogdir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'./callbacks'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0moutput_modle_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"fashion_mnist_model.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# 回调函数\n",
    "logdir = './callbacks'\n",
    "if not os.path.exists(logdir):\n",
    "    os.mkdir(logdir)\n",
    "output_modle_file = os.path.join(logdir, \"fashion_mnist_model.h5\")\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.TensorBoard(logdir),\n",
    "    keras.callbacks.ModelCheckpoint(output_modle_file, save_best_only = True),\n",
    "    # 由于epochs设置的比较小，可能不会触发，可以将epochs调大点，看看EarlyStopping的运行情况\n",
    "    keras.callbacks.EarlyStopping(patience=5, min_delta=1e-3),\n",
    "]\n",
    "# 数据的训练\n",
    "history = model.fit(x_train_scaled, y_train, epochs=10,validation_data=(x_valid_scaled,y_valid))\n",
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## matloplib可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matloplib可视化\n",
    "def plot_learning_cruves(history):\n",
    "    pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "    plt.grid(True)\n",
    "    plt.gca().set_ylim(0,1)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加上Z_scores归一化,dnn后的损失图像：\n",
    "plot_learning_cruves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "### 关于梯度消失问题\n",
    "深度模型中可能出现的问题：参数众多，倒只训练不充分\n",
    "梯度消失问题：首先梯度下降是指，一个数按照其此点最大导数的反方向更新。\n",
    "对于一个多层次的神经网络来说，比目标函数比较远的但是梯度比较微小的现象。\n",
    "什么情况会导致？ 一般发生在深度模型中，根据链式法则：符合函数{f(g(x))}\n",
    "梯度下降的时候我们需要对每一个嵌套的复合函数进行求导再相乘，最后如果求出来的导数小于1，多此相乘就会导致梯度消失。\n",
    "1.01^99=37.8\n",
    "0.99^99=0.03\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.6.7 64-bit ('rec_env': virtualenv)",
   "language": "python",
   "name": "python36764bitrecenvvirtualenvc590a763a4564b6f98e8e2c90348aa96"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
