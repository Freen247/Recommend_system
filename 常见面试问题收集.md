## Basic_knowledge_learning
- 关键字怎么提取的，TF-IDF有改进么，怎么改进的
    TF（Term Frequency）词频，在文章中出现次数最多的词，然而文章中出现次数较多的词并不一定就是关键词，比如常见的对文章本身并没有多大意义的停用词。所以我们需要一个重要性调整系数来衡量一个词是不是常见词。该权重为IDF（Inverse Document Frequency）逆文档频率，它的大小与一个词的常见程度成反比。在我们得到词频（TF）和逆文档频率（IDF）以后，将两个值相乘，即可得到一个词的TF-IDF值，某个词对文章的重要性越高，其TF-IDF值就越大，所以排在最前面的几个词就是文章的关键词。
- xgboost的原理
- SVM原始问题为什么要转化为对偶问题，为什么对偶问题就好求解，原始问题不能求解么
- K-means 中我想聚成100类 结果发现只能聚成98类，为什么
- 进程中的内存分段是怎样的
- GBDT的原理，以及常用的调参的参数
- xgboost的跟GBDT比优点都有哪些
- L1、L2正则化，区别
- Xgboost中的行抽样，可以起到哪些作用
- 样本少了不是会过拟合么，为什么行抽样可以防止过拟合
- 常用的损失函数和适用场景
- LR和SVM原理
- LR和SVM这两个应用起来有什么不同
- PCA说一下
- 你都会什么聚类方法
- 模型的评价方法有哪些
- ROC怎么画
- 你知道SoftMax么
- 特征选择方法都有用过哪些
- 随机森林怎么进行特征选择
- 用过哪些机器学习算法
- 加密方法知道哪些
- MD5可逆么
- word2vec用过么
- 极大似然估计是什么意思
- 说一下随机森林和Adaboost，以及区别
- 说一下GBDT和Adaboost，以及区别
- 说一下LDA的原理
- 对于PCA，会有第一主成分、第二主成分，怎么为什么第一主成分是第一，原因是什么？
- PCA的主成分是怎么得到的
- 说一下SVM
- 面向对象的三要素
- 对深度学习了解多少
- 你觉得深度学习的方法和传统机器学习比，有什么大的优势
- 当我们要求准确率很高，但是不在意召回率的时候，可以怎样处理。
- 回归算法用于分类的阈值如何确定呢
- xgboost，说一下原理，步长如何设定
- k-means中的k如何确定呢？
- 除了k-means，还可以用什么聚类方法，或者你还熟悉什么聚类方法
- 层次聚类的话，你又如何判断聚成多少类合适？
- 朴素贝叶斯原理
- TF-IDF原理
- 性能评价指标，准确率召回率是怎么回事，二分类 和多分类的评价方法
- LDA你是怎么用的，LDA的表现如何，主题分的效果好不好
- 你觉得基于内容的方法和协同过滤有什么不同
- 常用的推荐算法都有什么
- 集成学习为什么要用简单的基学习器，不用一个复杂一点的学习器
- 非线性的数据，可以使用什么分类器进行分类
- LDA的原理是什么？
- 推荐的时候矩阵一定是稀疏的，对于这个稀疏矩阵应该如何处理？
- 如何从文档中提取关键字？
- 讲一讲tf-idf是什么意思
- hashmap你用过么，底层是如何实现的？
- 手撸代码，不用库函数求一个数的立方根，要求误差小于0.01
- 
## 专业知识归纳